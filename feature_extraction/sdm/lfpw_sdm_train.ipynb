{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!ls /kaggle/input/lfpw-labelled-face-parts-in-the-wild\n!conda install -c menpo cyvlfeat -y\n!conda install -c conda-forge menpo menpofit menpodetect -y\nimport menpo","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import menpo.io as mio\nfrom pathlib import Path\n\npath_to_lfpw = Path('/kaggle/input/lfpw-labelled-face-parts-in-the-wild')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import menpo.io as mio\n\ntraining_images = []\n# load landmarked images\nfor i in mio.import_images(path_to_lfpw / 'trainset', verbose=True):\n    # crop image\n    i = i.crop_to_landmarks_proportion(0.1)\n    # convert it to grayscale if needed\n    if i.n_channels == 3:\n        i = i.as_greyscale(mode='luminosity')\n    # append it to the list\n    training_images.append(i)\n    \nfor i in mio.import_images(path_to_lfpw / 'testset', verbose=True):\n    # crop image\n    i = i.crop_to_landmarks_proportion(0.1)\n    # convert it to grayscale if needed\n    if i.n_channels == 3:\n        i = i.as_greyscale(mode='luminosity')\n    # append it to the list\n    training_images.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from menpofit.sdm import RegularizedSDM\n# Note that we use fast dense sift features\n# and thus cyvlfeat must be installed (use conda)\nfrom menpo.feature import vector_128_dsift\n\nfitter = RegularizedSDM(\n    training_images, \n    verbose=True,\n    group='PTS',\n    diagonal=200,\n    n_perturbations=30,\n    n_iterations=2,\n    patch_features=vector_128_dsift,\n    patch_shape=(24, 24),\n    alpha=10\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(fitter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load test images\ntest_images = []\nfor i in mio.import_images(path_to_lfpw / 'testset' / '*.png', max_images=5, verbose=True):\n    # crop image\n    i = i.crop_to_landmarks_proportion(0.5)\n    # convert it to grayscale if needed\n    if i.n_channels == 3:\n        i = i.as_greyscale(mode='luminosity')\n    # append it to the list\n    test_images.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from menpofit.fitter import noisy_shape_from_bounding_box\n\nfitting_results = []\n\nfor i in test_images:\n    gt_s = i.landmarks['PTS'].lms\n    # generate perturbed landmarks\n    bb = noisy_shape_from_bounding_box(fitter.reference_shape.bounding_box(), \n                                       gt_s.bounding_box())\n    # fit image\n    fr = fitter.fit_from_bb(i, bb, gt_shape=gt_s) \n    fitting_results.append(fr)\n\n    # print fitting error\n    print(fr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fr = fitting_results[2]\nfr.image.view(new_figure=True);\nfr.final_shape.view();\n\nfr.image.view(new_figure=True);\nfr.initial_shape.view(marker_face_colour='blue');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"\ntest_img = mio.import_image(path_to_lfpw / 'testset/image_0003.png')\n\nfrom menpodetect.dlib.detect import DlibDetector\nimport dlib\nff_detector = dlib.get_frontal_face_detector()\nbboxes = DlibDetector(ff_detector)(test_img, greyscale=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img.rasterize_landmarks(group='dlib_0').view()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fr = fitter.fit_from_bb(test_img, bboxes[0], max_iters=100)\nfr.image.view(new_figure=True);\nfr.final_shape.view();\n\nfr.image.view(new_figure=True);\nfr.initial_shape.view(marker_face_colour='blue');","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}